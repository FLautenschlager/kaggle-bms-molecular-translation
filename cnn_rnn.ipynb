{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "substantial-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# our model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#import Levenshtein\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64\n",
    "image_shape_1 = 100\n",
    "image_shape_2 = image_shape_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-muscle",
   "metadata": {},
   "source": [
    "# Make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certain-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = \"data/bms-molecular-translation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expired-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(rootpath + \"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "binding-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (2424186, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "                                           file_path  \n",
       "0  data/bms-molecular-translation/train/0/0/0/000...  \n",
       "1  data/bms-molecular-translation/train/0/0/0/000...  \n",
       "2  data/bms-molecular-translation/train/0/0/0/000...  \n",
       "3  data/bms-molecular-translation/train/0/0/0/000...  \n",
       "4  data/bms-molecular-translation/train/0/0/0/000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return rootpath + \"train/{}/{}/{}/{}.png\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )\n",
    "\n",
    "train['file_path'] = train['image_id'].apply(get_train_file_path)\n",
    "\n",
    "print(f'train.shape: {train.shape}')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-trinity",
   "metadata": {},
   "source": [
    "## Preprocess label, tokenize etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "apart-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label(InChI):\n",
    "    return \"<{}>\".format(InChI.replace(\"InChI=1S/\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "front-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"InChI_clean\"] = train[\"InChI\"].apply(preprocess_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "married-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>file_path</th>\n",
       "      <th>InChI_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "      <td>&lt;C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "      <td>&lt;C21H30O4/c1-12(22)25-14-6-8-20(2)13(10-14)11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "      <td>&lt;C24H23N5O4/c1-14-13-15(7-8-17(14)28-12-10-20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "      <td>&lt;C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>data/bms-molecular-translation/train/0/0/0/000...</td>\n",
       "      <td>&lt;C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7-8)5-2-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  data/bms-molecular-translation/train/0/0/0/000...   \n",
       "1  data/bms-molecular-translation/train/0/0/0/000...   \n",
       "2  data/bms-molecular-translation/train/0/0/0/000...   \n",
       "3  data/bms-molecular-translation/train/0/0/0/000...   \n",
       "4  data/bms-molecular-translation/train/0/0/0/000...   \n",
       "\n",
       "                                         InChI_clean  \n",
       "0  <C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4...  \n",
       "1  <C21H30O4/c1-12(22)25-14-6-8-20(2)13(10-14)11-...  \n",
       "2  <C24H23N5O4/c1-14-13-15(7-8-17(14)28-12-10-20(...  \n",
       "3  <C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11...  \n",
       "4  <C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7-8)5-2-3...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "innovative-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"q\", filters=' ', lower=False, char_level=True)\n",
    "tokenizer.fit_on_texts(train[\"InChI_clean\"].values)\n",
    "tokenizer.word_index['q'] = 0\n",
    "tokenizer.index_word[0] = 'q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legitimate-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = max(tokenizer.index_word.keys())+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "federal-texas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424186, 396)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train[\"InChI_clean\"].values), padding='post')\n",
    "train_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = train_token.shape[1]\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-snake",
   "metadata": {},
   "source": [
    "## Create DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inside-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = train[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "emotional-valley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424186"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "framed-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.from_tensor_slices((paths, train_token))\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "#for f in list_ds.take(5):\n",
    "#    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-atlas",
   "metadata": {},
   "source": [
    "## Split DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broad-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939349\n",
      "484837\n"
     ]
    }
   ],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hollow-weekend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30302"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = tf.data.experimental.cardinality(train_ds).numpy() // BATCH_SIZE\n",
    "num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stuffed-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img)\n",
    "    img = tf.image.resize(img, (image_shape_1, image_shape_2))\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "preliminary-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "list_ds = list_ds.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bizarre-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, autotune=tf.data.AUTOTUNE):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=BUFFER_SIZE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=autotune)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "informed-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds, autotune=autotune)\n",
    "val_ds = configure_for_performance(val_ds, autotune=autotune)\n",
    "list_ds = configure_for_performance(list_ds, autotune=autotune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-northwest",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-rainbow",
   "metadata": {},
   "source": [
    "# ***** Encoder goes here ******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "smoking-guitar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = tf.keras.Sequential()\n",
    "encoder.add(tf.keras.layers.Conv2D(64, 3, input_shape=(image_shape_1, image_shape_2, 1), activation='relu'))\n",
    "encoder.add(tf.keras.layers.Conv2D(64, 5, activation='relu'))\n",
    "encoder.add(tf.keras.layers.Flatten())\n",
    "encoder.add(tf.keras.layers.Dense(features_shape, activation=\"relu\"))\n",
    "\n",
    "encoder.output_shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "grave-right",
   "metadata": {},
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "\n",
    "encoder = CNN_Encoder(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "standing-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    " \n",
    "    def call(self, x, features, hidden):\n",
    "        # defining attention as a separate model\n",
    "\n",
    "        # x shape == (batch_size, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        #x = tf.reshape(x, [x.shape[0], x.shape[2]])\n",
    "\n",
    "        # x shape after concatenation == (batch_size, embedding_dim + features)\n",
    "        x = tf.concat([tf.expand_dims(features, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output shape = (batch_size, units)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        # shape == (batch_size, units)\n",
    "        x = self.fc1(output)\n",
    "\n",
    "        # x shape == (batch_size * max_length, hidden_size)\n",
    "        #x = tf.reshape(x, (-1, x.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, state\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "empirical-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "#decoder.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-surveillance",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "compatible-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blocked-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/attention_rnn_train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alike-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    # restoring the latest checkpoint in checkpoint_path\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sharp-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell\n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "metallic-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "\n",
    "    # initializing the hidden state for each batch\n",
    "    # because the captions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<']] * target.shape[0], 1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions, hidden = decoder(dec_input, features, hidden)\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-legislature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0/30302 Loss 0.9994\n",
      "Epoch 1 Batch 100/30302 Loss 0.8416\n",
      "Epoch 1 Batch 200/30302 Loss 0.8015\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(train_ds):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {}/{} Loss {:.4f}'.format(\n",
    "              epoch + 1, batch, num_steps, batch_loss.numpy() / int(target.shape[1])))\n",
    "        if batch % 500 == 0 & batch > 0:\n",
    "            break\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        ckpt_manager.save()\n",
    "\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-fisher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "federal-example",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-20d9272aeb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_ds' is not defined"
     ]
    }
   ],
   "source": [
    "val_ds.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-marshall",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8217025b057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_tensor, target in val_ds:\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<']] * target.shape[0], 1)\n",
    "    \n",
    "    features = encoder(img_tensor)\n",
    "    pred_tens = tf.zeros(target.shape)\n",
    "    \n",
    "    for i in range(0, target.shape[1]):\n",
    "        # passing the features through the decoder\n",
    "        predictions, hidden = decoder(dec_input, features, hidden)\n",
    "        \n",
    "        pred_tens[:,i] = predictions\n",
    "\n",
    "        # using teacher forcing\n",
    "        #dec_input = tf.expand_dims(target[:, i], 1)\n",
    "        dec_input = predictions\n",
    "    \n",
    "    val_predictions.append((pred_tens.numpy(), targ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bms-molecular-translation",
   "language": "python",
   "name": "bms-molecular-translation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
