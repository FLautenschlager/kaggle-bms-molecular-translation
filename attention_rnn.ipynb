{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enhanced-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# our model focuses on during captioning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn includes many helpful utilities\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "above-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "# Shape of the vector extracted from InceptionV3 is (64, 2048)\n",
    "# These two variables represent that vector shape\n",
    "features_shape = 2048\n",
    "attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "separated-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = \"data/bms-molecular-translation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "developmental-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(rootpath + \"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generous-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (2424186, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../input/bms-molecular-translation/train_incep...  \n",
       "1  ../input/bms-molecular-translation/train_incep...  \n",
       "2  ../input/bms-molecular-translation/train_incep...  \n",
       "3  ../input/bms-molecular-translation/train_incep...  \n",
       "4  ../input/bms-molecular-translation/train_incep...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return \"../input/bms-molecular-translation/train_inception/{}/{}/{}/{}.npy\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )\n",
    "\n",
    "train['file_path'] = train['image_id'].apply(get_train_file_path)\n",
    "\n",
    "print(f'train.shape: {train.shape}')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "important-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label(InChI):\n",
    "    return \"<{}>\".format(InChI.replace(\"InChI=1S/\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bigger-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"InChI_clean\"] = train[\"InChI\"].apply(preprocess_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "junior-springer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>file_path</th>\n",
       "      <th>InChI_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000011a64c74</td>\n",
       "      <td>InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "      <td>&lt;C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000019cc0cd2</td>\n",
       "      <td>InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "      <td>&lt;C21H30O4/c1-12(22)25-14-6-8-20(2)13(10-14)11-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000252b6d2b</td>\n",
       "      <td>InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "      <td>&lt;C24H23N5O4/c1-14-13-15(7-8-17(14)28-12-10-20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026b49b7e</td>\n",
       "      <td>InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "      <td>&lt;C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000026fc6c36</td>\n",
       "      <td>InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...</td>\n",
       "      <td>../input/bms-molecular-translation/train_incep...</td>\n",
       "      <td>&lt;C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7-8)5-2-3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  000011a64c74  InChI=1S/C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12...   \n",
       "1  000019cc0cd2  InChI=1S/C21H30O4/c1-12(22)25-14-6-8-20(2)13(1...   \n",
       "2  0000252b6d2b  InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-1...   \n",
       "3  000026b49b7e  InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-...   \n",
       "4  000026fc6c36  InChI=1S/C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  ../input/bms-molecular-translation/train_incep...   \n",
       "1  ../input/bms-molecular-translation/train_incep...   \n",
       "2  ../input/bms-molecular-translation/train_incep...   \n",
       "3  ../input/bms-molecular-translation/train_incep...   \n",
       "4  ../input/bms-molecular-translation/train_incep...   \n",
       "\n",
       "                                         InChI_clean  \n",
       "0  <C13H20OS/c1-9(2)8-15-13-6-5-10(3)7-12(13)11(4...  \n",
       "1  <C21H30O4/c1-12(22)25-14-6-8-20(2)13(10-14)11-...  \n",
       "2  <C24H23N5O4/c1-14-13-15(7-8-17(14)28-12-10-20(...  \n",
       "3  <C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11...  \n",
       "4  <C10H19N3O2S/c1-15-10(14)12-8-4-6-13(7-8)5-2-3...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "noted-stuff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 396, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'InChI_token'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3825\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3826\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'InChI_token'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5291fda57e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InChI_token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InChI_clean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3243\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3245\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3830\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2730\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2732\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Playground/kaggle-bms-molecular-translation/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 396, placement implies 1"
     ]
    }
   ],
   "source": [
    "# tokenizing\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"q\", filters=' ', lower=False, char_level=True)\n",
    "tokenizer.fit_on_texts(train[\"InChI_clean\"].values)\n",
    "tokenizer.word_index['q'] = 0\n",
    "tokenizer.index_word[0] = 'q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "knowing-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max(tokenizer.index_word.keys())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adult-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train[\"InChI_clean\"].values), padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "macro-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 18,  2, ...,  0,  0,  0],\n",
       "       [19, 18,  4, ...,  0,  0,  0],\n",
       "       [19, 18,  4, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [19, 18,  4, ...,  0,  0,  0],\n",
       "       [19, 18,  2, ...,  0,  0,  0],\n",
       "       [19, 18,  2, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tribal-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = train[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "extreme-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "timely-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'../input/bms-molecular-translation/train_inception/b/2/b/b2b3e3c06fca.png'>, <tf.Tensor: shape=(396,), dtype=int32, numpy=\n",
      "array([19, 18,  2,  4, 10,  4,  2, 23,  5, 24, 17, 20,  2,  3,  5,  3,  9,\n",
      "        3,  2,  4,  7,  2, 12,  3,  4,  8,  2,  2,  7,  2,  9,  8, 13,  3,\n",
      "       15,  3, 14,  3,  2, 11,  3, 12,  3, 11,  3,  2, 16,  7, 15,  8,  2,\n",
      "        5, 17, 22, 11,  3, 12,  6, 14,  6,  2,  2,  3,  2,  4, 10,  6,  5,\n",
      "        3,  9,  6, 13,  6,  2,  9, 10,  4,  6,  2,  3,  4, 10,  5,  6,  7,\n",
      "       10,  4,  6,  2,  5,  6,  2, 11,  8, 21,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'../input/bms-molecular-translation/train_inception/5/f/e/5fec1a25233d.png'>, <tf.Tensor: shape=(396,), dtype=int32, numpy=\n",
      "array([19, 18,  2, 11, 10,  2, 15, 26, 23, 12, 24,  4, 17, 20,  2,  3,  9,\n",
      "        3,  2,  2,  3,  2,  4,  7,  2, 12,  8,  2,  5,  7,  2, 14,  3, 14,\n",
      "        3,  2, 13,  3,  2,  2,  8,  4,  4,  3, 12,  3, 11,  3,  2, 11,  7,\n",
      "       13,  3,  4,  4,  6,  4, 16,  3, 15,  7,  4,  8,  4,  5,  8,  2,  9,\n",
      "        3,  2, 15,  3,  2, 16,  7,  5,  8,  4,  9,  3,  4,  2,  3,  2,  9,\n",
      "       17, 22, 14, 10,  6,  9,  3, 13, 10,  4,  6,  2,  3,  5, 10,  5,  6,\n",
      "        7, 10,  6,  4, 16,  6,  4,  5,  8, 17, 28,  2, 11,  3, 17, 29,  2,\n",
      "       17, 30,  2, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'../input/bms-molecular-translation/train_inception/5/7/8/578fa47a0b76.png'>, <tf.Tensor: shape=(396,), dtype=int32, numpy=\n",
      "array([19, 18,  4, 16, 10,  2, 14, 18, 27, 23, 11, 24, 25, 17, 20,  2,  3,\n",
      "        2,  4,  7,  4,  8,  2, 14,  3,  4,  9,  3,  4, 11,  3,  2, 15,  3,\n",
      "        4, 16,  7,  4,  5,  3,  2, 11,  3, 15,  3, 11,  3, 12,  3,  2, 16,\n",
      "        3,  2, 12,  7,  2, 11,  8,  4, 12,  7,  2, 14,  8,  2, 15,  8,  4,\n",
      "       14,  3,  2,  2,  3,  2, 13,  7,  4, 13,  8,  4,  4,  3,  2,  9,  3,\n",
      "       14,  3,  9,  3,  5,  3, 13,  3,  2,  5,  7,  2,  9,  8,  4,  2, 17,\n",
      "       22,  5,  3,  2, 16,  6,  2,  4, 10,  6,  2,  2, 10,  4,  6,  2,  3,\n",
      "        4, 10,  5,  6,  7, 10,  6,  4,  4,  6,  4, 13,  8, 21,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'../input/bms-molecular-translation/train_inception/8/3/8/8380981e1be2.png'>, <tf.Tensor: shape=(396,), dtype=int32, numpy=\n",
      "array([19, 18,  2, 13, 10,  2, 12, 26,  4, 24, 17, 20,  2, 14,  3,  2, 11,\n",
      "        3, 13,  3,  5,  3, 12,  3,  2,  5,  7,  2, 13,  7,  2, 11,  8,  2,\n",
      "       15,  8,  2, 16,  3,  2, 12,  7,  4, 16,  8,  2,  9,  3, 14,  3,  2,\n",
      "        2,  3,  9,  3,  2,  3,  4,  3, 11,  3,  2,  4,  7,  2,  2,  8, 15,\n",
      "        3,  2,  9, 17, 22,  2,  3, 13,  6,  2,  9,  6,  2, 12,  6,  4, 16,\n",
      "       10,  6, 14,  3,  2, 16, 10,  4, 21,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'../input/bms-molecular-translation/train_inception/2/d/b/2db33ddd8210.png'>, <tf.Tensor: shape=(396,), dtype=int32, numpy=\n",
      "array([19, 18,  4,  2, 10,  4,  2, 23, 24,  5, 25, 17, 20,  4,  5,  3,  2,\n",
      "        5,  3, 13,  3,  2,  4,  3,  4,  4,  3,  4,  2,  7,  4,  9,  8,  4,\n",
      "       16,  3,  2, 14,  7,  4, 11,  3,  2, 11,  3,  2, 12,  3, 14,  3,  5,\n",
      "        3,  2,  3,  9,  3, 15,  3,  2, 12,  8,  2,  9,  3,  2, 15,  7,  4,\n",
      "       12,  3,  4, 16,  8,  2, 13,  3,  2, 16,  3, 11,  3,  4,  3, 12,  3,\n",
      "        2,  2,  3,  2, 13, 17, 22,  2,  3, 12,  6, 14,  3,  2,  2,  6,  2,\n",
      "        9,  6,  4,  5, 10,  6, 13,  6,  2,  4,  3,  2,  5,  6,  2, 11, 10,\n",
      "        4,  6,  7, 10,  6,  4,  4,  6,  4,  9,  8, 21,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "list_ds = tf.data.Dataset.from_tensor_slices((paths, train_token))\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "\n",
    "for f in list_ds.take(5):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brazilian-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939349\n",
      "484837\n"
     ]
    }
   ],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "global-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = tf.data.experimental.cardinality(train_ds).numpy() // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "international-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "allied-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(image_path, label):\n",
    "    img_tensor = np.load(image_path.decode('utf-8'))\n",
    "    return img_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "appointed-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rolled-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, autotune=tf.data.AUTOTUNE):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=BUFFER_SIZE)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=autotune)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds, batch_size=batch_size, autotune=autotune)\n",
    "val_ds = configure_for_performance(val_ds, batch_size=1, autotune=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden_size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "\n",
    "        # attention_hidden_layer shape == (batch_size, 64, units)\n",
    "        attention_hidden_layer = (tf.nn.tanh(self.W1(features) +\n",
    "                                             self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # score shape == (batch_size, 64, 1)\n",
    "        # This gives you an unnormalized score for each image feature.\n",
    "        score = self.V(attention_hidden_layer)\n",
    "\n",
    "        # attention_weights shape == (batch_size, 64, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.Model):\n",
    "    # Since you have already extracted the features and dumped it using pickle\n",
    "    # This encoder passes those features through a Fully connected layer\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        # shape after fc == (batch_size, 64, embedding_dim)\n",
    "        self.fc = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    " \n",
    "    def call(self, x, features, hidden):\n",
    "        # defining attention as a separate model\n",
    "        context_vector, attention_weights = self.attention(features, hidden)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # shape == (batch_size, max_length, hidden_size)\n",
    "        x = self.fc1(output)\n",
    "\n",
    "        # x shape == (batch_size * max_length, hidden_size)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "desperate-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30302"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/attention_rnn_train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer = optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "    # restoring the latest checkpoint in checkpoint_path\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding this in a separate cell because if you run the training cell\n",
    "# many times, the loss_plot array will be reset\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "\n",
    "    # initializing the hidden state for each batch\n",
    "    # because the captions are not related from image to image\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
    "\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = train_step(img_tensor, target)\n",
    "        total_loss += t_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot.append(total_loss / num_steps)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        ckpt_manager.save()\n",
    "\n",
    "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-soundtrack",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "concrete-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(rootpath + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "impossible-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (1616107, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>InChI</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000d2a601c</td>\n",
       "      <td>InChI=1S/H2O/h1H2</td>\n",
       "      <td>data/bms-molecular-translation/test/0/0/0/0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001f7fc849</td>\n",
       "      <td>InChI=1S/H2O/h1H2</td>\n",
       "      <td>data/bms-molecular-translation/test/0/0/0/0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000037687605</td>\n",
       "      <td>InChI=1S/H2O/h1H2</td>\n",
       "      <td>data/bms-molecular-translation/test/0/0/0/0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004b6d55b6</td>\n",
       "      <td>InChI=1S/H2O/h1H2</td>\n",
       "      <td>data/bms-molecular-translation/test/0/0/0/0000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004df0fe53</td>\n",
       "      <td>InChI=1S/H2O/h1H2</td>\n",
       "      <td>data/bms-molecular-translation/test/0/0/0/0000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id              InChI  \\\n",
       "0  00000d2a601c  InChI=1S/H2O/h1H2   \n",
       "1  00001f7fc849  InChI=1S/H2O/h1H2   \n",
       "2  000037687605  InChI=1S/H2O/h1H2   \n",
       "3  00004b6d55b6  InChI=1S/H2O/h1H2   \n",
       "4  00004df0fe53  InChI=1S/H2O/h1H2   \n",
       "\n",
       "                                           file_path  \n",
       "0  data/bms-molecular-translation/test/0/0/0/0000...  \n",
       "1  data/bms-molecular-translation/test/0/0/0/0000...  \n",
       "2  data/bms-molecular-translation/test/0/0/0/0000...  \n",
       "3  data/bms-molecular-translation/test/0/0/0/0000...  \n",
       "4  data/bms-molecular-translation/test/0/0/0/0000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return rootpath + \"test/{}/{}/{}/{}.png\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )\n",
    "\n",
    "test['file_path'] = test['image_id'].apply(get_train_file_path)\n",
    "\n",
    "print(f'train.shape: {test.shape}')\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "minute-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "continent-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "new_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(img_tensor_val):\n",
    "\n",
    "    hidden = decoder.reset_state(batch_size=1)\n",
    "\n",
    "\n",
    "    features = encoder(img_tensor_val)\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<']], 0)\n",
    "    result = []\n",
    "\n",
    "    for i in range(max_length):\n",
    "        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n",
    "\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "        result.append(tokenizer.index_word[predicted_id])\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '>':\n",
    "            return result, attention_plot\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "allied-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_id(filepath):\n",
    "    return filepath.split(\"/\")[-1].replace(\".png\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for path in test['file_path']:\n",
    "    img = load_image(path)\n",
    "    img_tensor_val = image_features_extract_model(img)\n",
    "    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n",
    "    prediction = evaluate(img_tensor_val)\n",
    "    result.append({\"image_id\": get_img_id(path), \"InChI\": prediction.replace(\"<\", \"InChI=1S/\").replace(\">\",\"\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"results_attention_rnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bms-molecular-translation",
   "language": "python",
   "name": "bms-molecular-translation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
